{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB3sNglQrnTN"
      },
      "source": [
        "Data comes from [The Extrasolar Planet Encyclopedia](http://exoplanet.eu/). Thanks to Ilya Marchenko for sharing this dataset on [Kaggle](https://www.kaggle.com/ilyamarchenko/full-exoplanet-catalog?select=exoplanet_confirm_and_candidates.csv)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "g2AaGqEU9bC1"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3BI5pE0bLfsB"
      },
      "outputs": [],
      "source": [
        "exo_full_dataset = pd.read_csv('/content/drive/My Drive/exoplanets.csv')\n",
        "exo_full_dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "97Titj3M_tmn"
      },
      "outputs": [],
      "source": [
        "exo = \"extract the features listed in the lesson here\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Jfak73vWDrX_"
      },
      "outputs": [],
      "source": [
        "print(\"\\nUnique values\\n\",exo.nunique())\n",
        "print(\"\\nNull values\\n\\n\", exo.isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKwGAw9-NQqS"
      },
      "source": [
        "## Create dummy example data\n",
        "\n",
        "For all techniques we'll first demonstrate them on the simple DataFrame created below, then on the more realistic CSV file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LCJ63eqvIbwq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "alien_species = {\"alien_height\":[80, 63, 70, 93, np.nan], \"alien_age\":[12, np.nan, 87, 415, 892], \"home_planet\":[\"Mars\", \"Jupiter\", \"Europa\", \"Mars\", \"Europa\"]}\n",
        "\n",
        "alien_df = pd.DataFrame(alien_species)\n",
        "alien_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJwieNn9ISaA"
      },
      "source": [
        "## Imputation\n",
        "First the simple DataFrame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng-iUCzzqj4d"
      },
      "source": [
        "### `alien_df` Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eJPkQ-KoNel2"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "features = \"extract alien height and alien age features here\"\n",
        "print(features.head(), \"\\n\")\n",
        "imp = SimpleImputer()\n",
        "imp.fit(features)\n",
        "imputed = imp.transform(features)\n",
        "\n",
        "# the rest of this code block reformats the data to print it in an educative way. don't sweat it!\n",
        "# scikit learn often strips the column headers (it's due to converting arrays to numpy for math), so add them back like so:\n",
        "imputed_alien_df = pd.DataFrame(imputed,columns=features.columns)\n",
        "print(imputed_alien_df.head())\n",
        "# adding back the categorical data\n",
        "imputed_alien_df[\"home_planet\"] = alien_df[\"home_planet\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLF_NofQNx7u"
      },
      "source": [
        "Now let's perform imputation on the exoplanets dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfP5unpVqpAq"
      },
      "source": [
        "### Exoplanets Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "esqekNcEN7PB"
      },
      "outputs": [],
      "source": [
        "exo_numbers = \"extract the exoplanet numerical feature data here\"\n",
        "print(exo.head())\n",
        "print(\"\\nNull values\\n\\n\", exo.isna().sum(), \"\\n\")\n",
        "imp = \"instantiate the SimpleImputer class here\"\n",
        "# ?\n",
        "# ?\n",
        "\n",
        "# reformatting the imputed data below\n",
        "imputed_exo_df = pd.DataFrame(imputed,columns=exo_numbers.columns)\n",
        "# adding back in the categorical data\n",
        "imputed_exo_df[\"planet_status\"] = exo[\"planet_status\"]\n",
        "print(imputed_exo_df.head())\n",
        "print(\"\\nNull values\\n\\n\", imputed_exo_df.isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51Xkz1fUIcJB"
      },
      "source": [
        "## One-Hot Encoding\n",
        "First the `alien_df` data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wkt0SNm7qzks"
      },
      "source": [
        "### `alien_df` Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3gwlg14IK7Hf"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [2])], remainder='passthrough')\n",
        "# passthrough means keep the columns that aren't encoded\n",
        "# now connect it to the imputed dataframe\n",
        "encoded_alien_array = np.array(ct.fit_transform(imputed_alien_df))\n",
        "print(imputed_alien_df.head(), \"\\n\")\n",
        "\n",
        "# one hot encoding returns an array which our ML algo assumes is a NumPy array\n",
        "# in the next two lines we reformat this data to be more readable\n",
        "enc_alien_df = pd.DataFrame(encoded_alien_array, columns=[\"europa\", \"jupiter\", \"mars\", \"alien_height\",\"alien_age\"])\n",
        "enc_alien_df = enc_alien_df.loc[:,[\"alien_height\",\"alien_age\",\"mars\",\"jupiter\",\"europa\"]]\n",
        "print(enc_alien_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D_8S4pEo6_4"
      },
      "source": [
        "Now the exoplanet dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Z1qGJ8Hq1cG"
      },
      "source": [
        "### Exoplanets Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KHQKMeJ8F6nZ"
      },
      "outputs": [],
      "source": [
        "print(imputed_exo_df.loc[:, \"planet_status\"].unique())\n",
        "imputed_exo_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JMFMq8kjqB6O"
      },
      "outputs": [],
      "source": [
        "ct = \"instantiate the ColumnTransformer class with the proper params here\"\n",
        "enc_exo = np.array(\"transform the label column here\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gvUub1QckTr5"
      },
      "outputs": [],
      "source": [
        "# in this code block, we'll simply make the output more readable\n",
        "\n",
        "enc_exo_df = pd.DataFrame(enc_exo)\n",
        "# we can use the 'set_option` method to show all the columns here\n",
        "# (the remaining columns wrap to the next line)\n",
        "pd.set_option('display.max_columns', 12)\n",
        "# same as last time, the next two lines just make our encoding readable\n",
        "enc_exo_df.columns = [\"candidate\",\"confirmed\",\"controversial\",\"retracted\",\"unconfirmed\", \"radius\",\"mass\", \"orbital_period\",\"star_distance\"]\n",
        "enc_exo_df = enc_exo_df.loc[:,[\"radius\",\"mass\",\"orbital_period\",\"star_distance\",\"candidate\",\"confirmed\",\"controversial\",\"retracted\",\"unconfirmed\"]]\n",
        "\n",
        "print(imputed_exo_df.head(), \"\\n\")\n",
        "print(enc_exo_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0eXqDNombOX"
      },
      "source": [
        "## Further Practice\n",
        "If you want to sharpen your skills, try feature scaling the exoplanet data below. Then you'd have a wholly preprocessed dataset!\n",
        "\n",
        "(Since the one-hot encoded data occurs within the normal range of standard deviation, you don't need to worry about scaling it.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vuipIATXnIRT"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# remember how this goes?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Imputation and Encoding Learner Version.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
